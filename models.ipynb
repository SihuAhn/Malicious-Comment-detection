{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataFrame을 넣고 실행하면 X_data, y_data, vocab_size, max_len를 돌려주는 get_X_y_vacabsize_maxlen method\n",
    "# @name   : get_X_y_vacabsize_maxlen\n",
    "# @pram   : DataFrame\n",
    "# @return : np.array, list, int, int\n",
    "def get_X_y_vacabsize_maxlen(df):\n",
    "    X_data = df['comment']\n",
    "    y_data = df['bad']\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(X_data)\n",
    "    sequences = tokenizer.texts_to_sequences(X_data)\n",
    "    df['comment'] = sequences\n",
    "    word_to_index = tokenizer.word_index\n",
    "    vocab_size = len(word_to_index)+1\n",
    "    max_len = max(len(l) for l in sequences)\n",
    "    data = pad_sequences(sequences, maxlen=max_len)\n",
    "    X_data = (data)\n",
    "    y_data = df['bad']\n",
    "    return X_data, y_data, vocab_size, max_len\n",
    "\n",
    "# vocab_size, max_len를 넣고 실행하면 CNN모델을 만들어주는 CNNmodel method\n",
    "# @name   : CNNmodel\n",
    "# @pram   : int, int\n",
    "# @return : Sequential\n",
    "def CNNmodel(vocab_size, max_len):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 32, input_length=max_len))\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# vocab_size, max_len를 넣고 실행하면 LSTM모델을 만들어주는 LSTMmodel method\n",
    "# @name   : LSTMmodel\n",
    "# @pram   : int, int\n",
    "# @return : Sequential\n",
    "def LSTMmodel(vocab_size,max_len):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 32))\n",
    "    model.add(LSTM(max_len, activation='tanh'))\n",
    "    model.add(Dense(units=1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# vocab_size를 넣으면 RNN모델을 만들어주는 RNNmodel method\n",
    "# @name   : RNNmodel\n",
    "# @pram   : int\n",
    "# @return : Sequential\n",
    "def RNNmodel(vocab_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 32)) # 임베딩 벡터의 차원은 32\n",
    "    model.add(SimpleRNN(32)) # RNN 셀의 hidden_size는 32\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pyprind\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, SimpleRNN, Embedding, Dense, Activation, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 처리 방식에 따른 네 가지 데이터 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sulliComments_nouns = pd.read_csv('sulliComments_nouns.csv',encoding='cp949')\n",
    "sulliComments_nounsJaso = pd.read_csv('sulliComments_nounsJaso.csv',encoding='cp949')\n",
    "sulliComments_morps = pd.read_csv('sulliComments_morps.csv',encoding='cp949')\n",
    "sulliComments_morpsJaso = pd.read_csv('sulliComments_morpsJaso.csv',encoding='cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 처리 방식 별 X, y, vocab_size, max_len 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_X_data,nouns_y_data, nouns_vocab_size, nouns_max_len = get_X_y_vacabsize_maxlen(sulliComments_nouns)\n",
    "nounsJaso_X_data,nounsJaso_y_data, nounsJaso_vocab_size, nounsJaso_max_len = get_X_y_vacabsize_maxlen(sulliComments_nounsJaso)\n",
    "morps_X_data,morps_y_data, morps_vocab_size, morps_max_len = get_X_y_vacabsize_maxlen(sulliComments_morps)\n",
    "morpsJaso_X_data,morpsJaso_y_data, morpsJaso_vocab_size, morpsJaso_max_len = get_X_y_vacabsize_maxlen(sulliComments_morpsJaso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 처리 방식 별 train, valid, test set 생성(80:20rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_X_train, nouns_X_test, nouns_y_train, nouns_y_test = train_test_split(nouns_X_data, nouns_y_data, test_size=0.2, random_state=0)\n",
    "nouns_X_train, nouns_X_valid, nouns_y_train, nouns_y_valid = train_test_split(nouns_X_train, nouns_y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "nounsJaso_X_train, nounsJaso_X_test, nounsJaso_y_train, nounsJaso_y_test = train_test_split(nounsJaso_X_data, nounsJaso_y_data, test_size=0.2, random_state=0)\n",
    "nounsJaso_X_train, nounsJaso_X_valid, nounsJaso_y_train, nounsJaso_y_valid = train_test_split(nounsJaso_X_train, nounsJaso_y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "morps_X_train, morps_X_test, morps_y_train, morps_y_test = train_test_split(morps_X_data, morps_y_data, test_size=0.2, random_state=0)\n",
    "morps_X_train, morps_X_valid, morps_y_train, morps_y_valid = train_test_split(morps_X_train, morps_y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "morpsJaso_X_train, morpsJaso_X_test, morpsJaso_y_train, morpsJaso_y_test = train_test_split(morpsJaso_X_data, morpsJaso_y_data, test_size=0.2, random_state=0)\n",
    "morpsJaso_X_train, morpsJaso_X_valid, morpsJaso_y_train, morpsJaso_y_valid = train_test_split(morpsJaso_X_train, morpsJaso_y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 처리 방식 별 12개의 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lmgtt\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\lmgtt\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\lmgtt\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "nouns_RNN_model = RNNmodel(nouns_vocab_size)\n",
    "nouns_LSTM_model = LSTMmodel(nouns_vocab_size, nouns_max_len)\n",
    "nouns_CNN_model = CNNmodel(nouns_vocab_size, nouns_max_len)\n",
    "\n",
    "nounsJaso_RNN_model = RNNmodel(nounsJaso_vocab_size)\n",
    "nounsJaso_LSTM_model = LSTMmodel(nounsJaso_vocab_size, nounsJaso_max_len)\n",
    "nounsJaso_CNN_model = CNNmodel(nounsJaso_vocab_size, nounsJaso_max_len)\n",
    "\n",
    "morps_RNN_model = RNNmodel(morps_vocab_size)\n",
    "morps_LSTM_model = LSTMmodel(morps_vocab_size, morps_max_len)\n",
    "morps_CNN_model = CNNmodel(morps_vocab_size, morps_max_len)\n",
    "\n",
    "morpsJaso_RNN_model = RNNmodel(morpsJaso_vocab_size)\n",
    "morpsJaso_LSTM_model = LSTMmodel(morpsJaso_vocab_size, morpsJaso_max_len)\n",
    "morpsJaso_CNN_model = CNNmodel(morpsJaso_vocab_size, morpsJaso_max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 768 samples, validate on 192 samples\n",
      "Epoch 1/15\n",
      "768/768 [==============================] - 1s 1ms/sample - loss: 0.6722 - acc: 0.5911 - val_loss: 0.6394 - val_acc: 0.7604\n",
      "Epoch 2/15\n",
      "768/768 [==============================] - 0s 243us/sample - loss: 0.5725 - acc: 0.8737 - val_loss: 0.5795 - val_acc: 0.7604\n",
      "Epoch 3/15\n",
      "768/768 [==============================] - 0s 273us/sample - loss: 0.4654 - acc: 0.8971 - val_loss: 0.5270 - val_acc: 0.8177\n",
      "Epoch 4/15\n",
      "768/768 [==============================] - 0s 243us/sample - loss: 0.3558 - acc: 0.9193 - val_loss: 0.4598 - val_acc: 0.8333\n",
      "Epoch 5/15\n",
      "768/768 [==============================] - 0s 365us/sample - loss: 0.2813 - acc: 0.9271 - val_loss: 0.4108 - val_acc: 0.8438\n",
      "Epoch 6/15\n",
      "768/768 [==============================] - 0s 335us/sample - loss: 0.2217 - acc: 0.9440 - val_loss: 0.3922 - val_acc: 0.8438\n",
      "Epoch 7/15\n",
      "768/768 [==============================] - 0s 242us/sample - loss: 0.1763 - acc: 0.9609 - val_loss: 0.3990 - val_acc: 0.8333\n",
      "Epoch 8/15\n",
      "768/768 [==============================] - 0s 243us/sample - loss: 0.1536 - acc: 0.9688 - val_loss: 0.3450 - val_acc: 0.8490\n",
      "Epoch 9/15\n",
      "768/768 [==============================] - 0s 245us/sample - loss: 0.1232 - acc: 0.9727 - val_loss: 0.3314 - val_acc: 0.8542\n",
      "Epoch 10/15\n",
      "768/768 [==============================] - 0s 252us/sample - loss: 0.1067 - acc: 0.9753 - val_loss: 0.3183 - val_acc: 0.8594\n",
      "Epoch 11/15\n",
      "768/768 [==============================] - 0s 244us/sample - loss: 0.0896 - acc: 0.9792 - val_loss: 0.3221 - val_acc: 0.8490\n",
      "Epoch 12/15\n",
      "768/768 [==============================] - 0s 353us/sample - loss: 0.0802 - acc: 0.9805 - val_loss: 0.3138 - val_acc: 0.8542\n",
      "Epoch 13/15\n",
      "768/768 [==============================] - 0s 245us/sample - loss: 0.0714 - acc: 0.9805 - val_loss: 0.3055 - val_acc: 0.8594\n",
      "Epoch 14/15\n",
      "768/768 [==============================] - 0s 321us/sample - loss: 0.0643 - acc: 0.9844 - val_loss: 0.3478 - val_acc: 0.8490\n",
      "Epoch 15/15\n",
      "768/768 [==============================] - 0s 306us/sample - loss: 0.0572 - acc: 0.9844 - val_loss: 0.3398 - val_acc: 0.8594\n",
      "240/240 [==============================] - 0s 133us/sample - loss: 0.3347 - acc: 0.8542\n",
      "nouns_RNN 테스트 정확도: 0.8542\n"
     ]
    }
   ],
   "source": [
    "nouns_RNN_history = nouns_RNN_model.fit(nouns_X_train, nouns_y_train, epochs=15, batch_size=60, validation_data=(nouns_X_valid,nouns_y_valid))\n",
    "print(\"nouns_RNN 테스트 정확도: %.4f\" % (nouns_RNN_model.evaluate(nouns_X_test, nouns_y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 768 samples, validate on 192 samples\n",
      "Epoch 1/7\n",
      "768/768 [==============================] - 3s 3ms/sample - loss: 1.4563 - acc: 0.4948 - val_loss: 0.7817 - val_acc: 0.5052\n",
      "Epoch 2/7\n",
      "768/768 [==============================] - 1s 2ms/sample - loss: 0.7037 - acc: 0.5651 - val_loss: 0.6292 - val_acc: 0.6927\n",
      "Epoch 3/7\n",
      "768/768 [==============================] - 1s 2ms/sample - loss: 0.6381 - acc: 0.6328 - val_loss: 0.5708 - val_acc: 0.7708\n",
      "Epoch 4/7\n",
      "768/768 [==============================] - 1s 2ms/sample - loss: 0.5471 - acc: 0.7305 - val_loss: 0.5121 - val_acc: 0.7865\n",
      "Epoch 5/7\n",
      "768/768 [==============================] - 1s 2ms/sample - loss: 0.4565 - acc: 0.8320 - val_loss: 0.4334 - val_acc: 0.8698\n",
      "Epoch 6/7\n",
      "768/768 [==============================] - 1s 2ms/sample - loss: 0.3298 - acc: 0.8945 - val_loss: 0.3580 - val_acc: 0.8802\n",
      "Epoch 7/7\n",
      "768/768 [==============================] - 1s 2ms/sample - loss: 0.2085 - acc: 0.9414 - val_loss: 0.5043 - val_acc: 0.8802\n",
      "240/240 [==============================] - 0s 544us/sample - loss: 0.3442 - acc: 0.8708\n",
      "nouns_LSTM 테스트 정확도: 0.8708\n"
     ]
    }
   ],
   "source": [
    "nouns_LSTM_history = nouns_LSTM_model.fit(nouns_X_train, nouns_y_train, epochs=7, batch_size=60, validation_data=(nouns_X_valid,nouns_y_valid))\n",
    "print(\"nouns_LSTM 테스트 정확도: %.4f\" % (nouns_LSTM_model.evaluate(nouns_X_test, nouns_y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 768 samples, validate on 192 samples\n",
      "Epoch 1/17\n",
      "768/768 [==============================] - 1s 887us/sample - loss: 0.6922 - acc: 0.5508 - val_loss: 0.6889 - val_acc: 0.6979\n",
      "Epoch 2/17\n",
      "768/768 [==============================] - 0s 122us/sample - loss: 0.6797 - acc: 0.7891 - val_loss: 0.6777 - val_acc: 0.7708\n",
      "Epoch 3/17\n",
      "768/768 [==============================] - 0s 119us/sample - loss: 0.6508 - acc: 0.8372 - val_loss: 0.6445 - val_acc: 0.8021\n",
      "Epoch 4/17\n",
      "768/768 [==============================] - 0s 114us/sample - loss: 0.5742 - acc: 0.9180 - val_loss: 0.5580 - val_acc: 0.8229\n",
      "Epoch 5/17\n",
      "768/768 [==============================] - 0s 162us/sample - loss: 0.4221 - acc: 0.9297 - val_loss: 0.4224 - val_acc: 0.8802\n",
      "Epoch 6/17\n",
      "768/768 [==============================] - 0s 119us/sample - loss: 0.2575 - acc: 0.9479 - val_loss: 0.3499 - val_acc: 0.8802\n",
      "Epoch 7/17\n",
      "768/768 [==============================] - 0s 117us/sample - loss: 0.1630 - acc: 0.9596 - val_loss: 0.3027 - val_acc: 0.8854\n",
      "Epoch 8/17\n",
      "768/768 [==============================] - 0s 126us/sample - loss: 0.1095 - acc: 0.9701 - val_loss: 0.2925 - val_acc: 0.8802\n",
      "Epoch 9/17\n",
      "768/768 [==============================] - 0s 129us/sample - loss: 0.0809 - acc: 0.9818 - val_loss: 0.2840 - val_acc: 0.8958\n",
      "Epoch 10/17\n",
      "768/768 [==============================] - 0s 135us/sample - loss: 0.0678 - acc: 0.9831 - val_loss: 0.2899 - val_acc: 0.8854\n",
      "Epoch 11/17\n",
      "768/768 [==============================] - 0s 119us/sample - loss: 0.0606 - acc: 0.9844 - val_loss: 0.2930 - val_acc: 0.8958\n",
      "Epoch 12/17\n",
      "768/768 [==============================] - 0s 116us/sample - loss: 0.0520 - acc: 0.9844 - val_loss: 0.2921 - val_acc: 0.8854\n",
      "Epoch 13/17\n",
      "768/768 [==============================] - 0s 122us/sample - loss: 0.0511 - acc: 0.9844 - val_loss: 0.2964 - val_acc: 0.9010\n",
      "Epoch 14/17\n",
      "768/768 [==============================] - 0s 119us/sample - loss: 0.0449 - acc: 0.9844 - val_loss: 0.3017 - val_acc: 0.9010\n",
      "Epoch 15/17\n",
      "768/768 [==============================] - 0s 144us/sample - loss: 0.0433 - acc: 0.9857 - val_loss: 0.3021 - val_acc: 0.8906\n",
      "Epoch 16/17\n",
      "768/768 [==============================] - 0s 125us/sample - loss: 0.0416 - acc: 0.9857 - val_loss: 0.2997 - val_acc: 0.8854\n",
      "Epoch 17/17\n",
      "768/768 [==============================] - 0s 119us/sample - loss: 0.0379 - acc: 0.9883 - val_loss: 0.3043 - val_acc: 0.9062\n",
      "240/240 [==============================] - 0s 75us/sample - loss: 0.2567 - acc: 0.9042\n",
      "nouns_CNN 테스트 정확도: 0.9042\n"
     ]
    }
   ],
   "source": [
    "nouns_CNN_history = nouns_CNN_model.fit(nouns_X_train, nouns_y_train, epochs=17, batch_size=60, validation_data=(nouns_X_valid,nouns_y_valid))\n",
    "print(\"nouns_CNN 테스트 정확도: %.4f\" % (nouns_CNN_model.evaluate(nouns_X_test, nouns_y_test)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 768 samples, validate on 192 samples\n",
      "Epoch 1/15\n",
      "768/768 [==============================] - 1s 2ms/sample - loss: 0.6613 - acc: 0.6198 - val_loss: 0.6227 - val_acc: 0.6094\n",
      "Epoch 2/15\n",
      "768/768 [==============================] - 0s 445us/sample - loss: 0.5204 - acc: 0.7917 - val_loss: 0.5153 - val_acc: 0.7917\n",
      "Epoch 3/15\n",
      "768/768 [==============================] - 0s 462us/sample - loss: 0.4098 - acc: 0.8581 - val_loss: 0.4058 - val_acc: 0.8333\n",
      "Epoch 4/15\n",
      "768/768 [==============================] - 0s 596us/sample - loss: 0.3571 - acc: 0.8815 - val_loss: 0.3634 - val_acc: 0.8646\n",
      "Epoch 5/15\n",
      "768/768 [==============================] - 0s 467us/sample - loss: 0.2918 - acc: 0.9141 - val_loss: 0.3277 - val_acc: 0.8750\n",
      "Epoch 6/15\n",
      "768/768 [==============================] - 0s 497us/sample - loss: 0.2354 - acc: 0.9362 - val_loss: 0.5273 - val_acc: 0.6875\n",
      "Epoch 7/15\n",
      "768/768 [==============================] - 0s 462us/sample - loss: 0.2324 - acc: 0.9128 - val_loss: 0.3375 - val_acc: 0.8490\n",
      "Epoch 8/15\n",
      "768/768 [==============================] - 0s 471us/sample - loss: 0.1905 - acc: 0.9375 - val_loss: 0.2830 - val_acc: 0.9010\n",
      "Epoch 9/15\n",
      "768/768 [==============================] - 0s 484us/sample - loss: 0.1883 - acc: 0.9414 - val_loss: 0.2996 - val_acc: 0.9010\n",
      "Epoch 10/15\n",
      "768/768 [==============================] - 0s 436us/sample - loss: 0.1435 - acc: 0.9609 - val_loss: 0.2837 - val_acc: 0.9010\n",
      "Epoch 11/15\n",
      "768/768 [==============================] - 0s 564us/sample - loss: 0.1228 - acc: 0.9701 - val_loss: 0.2918 - val_acc: 0.8958\n",
      "Epoch 12/15\n",
      "768/768 [==============================] - 0s 503us/sample - loss: 0.1267 - acc: 0.9648 - val_loss: 0.2785 - val_acc: 0.8958\n",
      "Epoch 13/15\n",
      "768/768 [==============================] - 0s 531us/sample - loss: 0.1146 - acc: 0.9570 - val_loss: 0.2930 - val_acc: 0.8802\n",
      "Epoch 14/15\n",
      "768/768 [==============================] - 0s 525us/sample - loss: 0.0930 - acc: 0.9727 - val_loss: 0.2719 - val_acc: 0.9167\n",
      "Epoch 15/15\n",
      "768/768 [==============================] - 0s 516us/sample - loss: 0.0892 - acc: 0.9766 - val_loss: 0.2958 - val_acc: 0.8906\n",
      "240/240 [==============================] - 0s 229us/sample - loss: 0.2735 - acc: 0.8917\n",
      "nounsJaso_RNN 테스트 정확도: 0.8917\n"
     ]
    }
   ],
   "source": [
    "nounsJaso_RNN_history = nounsJaso_RNN_model.fit(nounsJaso_X_train, nounsJaso_y_train, epochs=15, batch_size=60, validation_data=(nounsJaso_X_valid,nounsJaso_y_valid))\n",
    "print(\"nounsJaso_RNN 테스트 정확도: %.4f\" % (nounsJaso_RNN_model.evaluate(nounsJaso_X_test, nounsJaso_y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 768 samples, validate on 192 samples\n",
      "Epoch 1/7\n",
      "768/768 [==============================] - 6s 7ms/sample - loss: 1.4282 - acc: 0.5026 - val_loss: 0.6434 - val_acc: 0.6042\n",
      "Epoch 2/7\n",
      "768/768 [==============================] - 4s 5ms/sample - loss: 0.7046 - acc: 0.5182 - val_loss: 0.6338 - val_acc: 0.5052\n",
      "Epoch 3/7\n",
      "768/768 [==============================] - 4s 5ms/sample - loss: 0.6090 - acc: 0.6576 - val_loss: 0.5423 - val_acc: 0.7604\n",
      "Epoch 4/7\n",
      "768/768 [==============================] - 5s 7ms/sample - loss: 0.5202 - acc: 0.8060 - val_loss: 0.4656 - val_acc: 0.8385\n",
      "Epoch 5/7\n",
      "768/768 [==============================] - 4s 5ms/sample - loss: 0.4234 - acc: 0.8542 - val_loss: 0.3625 - val_acc: 0.8698\n",
      "Epoch 6/7\n",
      "768/768 [==============================] - 4s 5ms/sample - loss: 0.3141 - acc: 0.9036 - val_loss: 0.3580 - val_acc: 0.8906\n",
      "Epoch 7/7\n",
      "768/768 [==============================] - 4s 5ms/sample - loss: 0.2208 - acc: 0.9284 - val_loss: 0.3481 - val_acc: 0.9062\n",
      "240/240 [==============================] - 0s 2ms/sample - loss: 0.3371 - acc: 0.8917\n",
      "nounsJaso_LSTM 테스트 정확도: 0.8917\n"
     ]
    }
   ],
   "source": [
    "nounsJaso_LSTM_history = nounsJaso_LSTM_model.fit(nounsJaso_X_train, nounsJaso_y_train, epochs=7, batch_size=60, validation_data=(nounsJaso_X_valid,nounsJaso_y_valid))\n",
    "print(\"nounsJaso_LSTM 테스트 정확도: %.4f\" % (nounsJaso_LSTM_model.evaluate(nounsJaso_X_test, nounsJaso_y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 768 samples, validate on 192 samples\n",
      "Epoch 1/17\n",
      "768/768 [==============================] - 1s 1ms/sample - loss: 0.6931 - acc: 0.4974 - val_loss: 0.6893 - val_acc: 0.5052\n",
      "Epoch 2/17\n",
      "768/768 [==============================] - 0s 178us/sample - loss: 0.6855 - acc: 0.5091 - val_loss: 0.6789 - val_acc: 0.5000\n",
      "Epoch 3/17\n",
      "768/768 [==============================] - 0s 209us/sample - loss: 0.6680 - acc: 0.6250 - val_loss: 0.6462 - val_acc: 0.7604\n",
      "Epoch 4/17\n",
      "768/768 [==============================] - 0s 200us/sample - loss: 0.6184 - acc: 0.7552 - val_loss: 0.5695 - val_acc: 0.7917\n",
      "Epoch 5/17\n",
      "768/768 [==============================] - 0s 177us/sample - loss: 0.5159 - acc: 0.8802 - val_loss: 0.4429 - val_acc: 0.8750\n",
      "Epoch 6/17\n",
      "768/768 [==============================] - 0s 191us/sample - loss: 0.3754 - acc: 0.9049 - val_loss: 0.3411 - val_acc: 0.8750\n",
      "Epoch 7/17\n",
      "768/768 [==============================] - 0s 208us/sample - loss: 0.2652 - acc: 0.9154 - val_loss: 0.2927 - val_acc: 0.8802\n",
      "Epoch 8/17\n",
      "768/768 [==============================] - 0s 197us/sample - loss: 0.1959 - acc: 0.9362 - val_loss: 0.2723 - val_acc: 0.8906\n",
      "Epoch 9/17\n",
      "768/768 [==============================] - 0s 213us/sample - loss: 0.1555 - acc: 0.9505 - val_loss: 0.2579 - val_acc: 0.8958\n",
      "Epoch 10/17\n",
      "768/768 [==============================] - 0s 252us/sample - loss: 0.1307 - acc: 0.9609 - val_loss: 0.2460 - val_acc: 0.9010\n",
      "Epoch 11/17\n",
      "768/768 [==============================] - 0s 216us/sample - loss: 0.1118 - acc: 0.9714 - val_loss: 0.2391 - val_acc: 0.9062\n",
      "Epoch 12/17\n",
      "768/768 [==============================] - 0s 218us/sample - loss: 0.1050 - acc: 0.9661 - val_loss: 0.2677 - val_acc: 0.8958\n",
      "Epoch 13/17\n",
      "768/768 [==============================] - 0s 264us/sample - loss: 0.1010 - acc: 0.9714 - val_loss: 0.2641 - val_acc: 0.9062\n",
      "Epoch 14/17\n",
      "768/768 [==============================] - 0s 204us/sample - loss: 0.0928 - acc: 0.9727 - val_loss: 0.2381 - val_acc: 0.8958\n",
      "Epoch 15/17\n",
      "768/768 [==============================] - 0s 217us/sample - loss: 0.0840 - acc: 0.9753 - val_loss: 0.2463 - val_acc: 0.9062\n",
      "Epoch 16/17\n",
      "768/768 [==============================] - 0s 205us/sample - loss: 0.0793 - acc: 0.9805 - val_loss: 0.2484 - val_acc: 0.8906\n",
      "Epoch 17/17\n",
      "768/768 [==============================] - 0s 306us/sample - loss: 0.0745 - acc: 0.9805 - val_loss: 0.2637 - val_acc: 0.8958\n",
      "240/240 [==============================] - 0s 129us/sample - loss: 0.2332 - acc: 0.9125\n",
      "nounsJaso_CNN 테스트 정확도: 0.9125\n"
     ]
    }
   ],
   "source": [
    "nounsJaso_CNN_history = nounsJaso_CNN_model.fit(nounsJaso_X_train, nounsJaso_y_train, epochs=17, batch_size=60, validation_data=(nounsJaso_X_valid,nounsJaso_y_valid))\n",
    "print(\"nounsJaso_CNN 테스트 정확도: %.4f\" % (nounsJaso_CNN_model.evaluate(nounsJaso_X_test, nounsJaso_y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 768 samples, validate on 192 samples\n",
      "Epoch 1/15\n",
      "768/768 [==============================] - 1s 2ms/sample - loss: 0.6776 - acc: 0.5534 - val_loss: 0.6699 - val_acc: 0.5365\n",
      "Epoch 2/15\n",
      "768/768 [==============================] - 1s 845us/sample - loss: 0.5968 - acc: 0.7826 - val_loss: 0.6198 - val_acc: 0.7135\n",
      "Epoch 3/15\n",
      "768/768 [==============================] - 1s 677us/sample - loss: 0.5029 - acc: 0.8997 - val_loss: 0.5813 - val_acc: 0.7396\n",
      "Epoch 4/15\n",
      "768/768 [==============================] - 1s 877us/sample - loss: 0.4070 - acc: 0.9388 - val_loss: 0.5370 - val_acc: 0.7604\n",
      "Epoch 5/15\n",
      "768/768 [==============================] - 1s 675us/sample - loss: 0.3330 - acc: 0.9427 - val_loss: 0.5031 - val_acc: 0.7708\n",
      "Epoch 6/15\n",
      "768/768 [==============================] - 1s 699us/sample - loss: 0.2503 - acc: 0.9701 - val_loss: 0.4613 - val_acc: 0.7812\n",
      "Epoch 7/15\n",
      "768/768 [==============================] - 0s 643us/sample - loss: 0.1858 - acc: 0.9805 - val_loss: 0.4549 - val_acc: 0.8073\n",
      "Epoch 8/15\n",
      "768/768 [==============================] - 1s 809us/sample - loss: 0.1424 - acc: 0.9818 - val_loss: 0.4226 - val_acc: 0.7917\n",
      "Epoch 9/15\n",
      "768/768 [==============================] - 1s 680us/sample - loss: 0.1060 - acc: 0.9922 - val_loss: 0.4001 - val_acc: 0.8177\n",
      "Epoch 10/15\n",
      "768/768 [==============================] - 1s 744us/sample - loss: 0.0890 - acc: 0.9844 - val_loss: 0.3618 - val_acc: 0.8438\n",
      "Epoch 11/15\n",
      "768/768 [==============================] - 0s 639us/sample - loss: 0.0677 - acc: 0.9922 - val_loss: 0.3932 - val_acc: 0.8385\n",
      "Epoch 12/15\n",
      "768/768 [==============================] - 1s 699us/sample - loss: 0.0547 - acc: 0.9922 - val_loss: 0.3739 - val_acc: 0.8333\n",
      "Epoch 13/15\n",
      "768/768 [==============================] - 0s 618us/sample - loss: 0.0401 - acc: 0.9961 - val_loss: 0.3439 - val_acc: 0.8594\n",
      "Epoch 14/15\n",
      "768/768 [==============================] - 1s 690us/sample - loss: 0.0325 - acc: 0.9935 - val_loss: 0.3113 - val_acc: 0.8854\n",
      "Epoch 15/15\n",
      "768/768 [==============================] - 1s 656us/sample - loss: 0.0255 - acc: 0.9974 - val_loss: 0.3729 - val_acc: 0.8594\n",
      "240/240 [==============================] - 0s 332us/sample - loss: 0.3579 - acc: 0.8458\n",
      "morps_RNN 테스트 정확도: 0.8458\n"
     ]
    }
   ],
   "source": [
    "morps_RNN_history = morps_RNN_model.fit(morps_X_train, morps_y_train, epochs=15, batch_size=60, validation_data=(morps_X_valid,morps_y_valid))\n",
    "print(\"morps_RNN 테스트 정확도: %.4f\" % (morps_RNN_model.evaluate(morps_X_test, morps_y_test)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 768 samples, validate on 192 samples\n",
      "Epoch 1/7\n",
      "768/768 [==============================] - 10s 13ms/sample - loss: 1.7651 - acc: 0.4961 - val_loss: 0.7289 - val_acc: 0.5052\n",
      "Epoch 2/7\n",
      "768/768 [==============================] - 8s 11ms/sample - loss: 0.7590 - acc: 0.4948 - val_loss: 0.6585 - val_acc: 0.5052\n",
      "Epoch 3/7\n",
      "768/768 [==============================] - 8s 11ms/sample - loss: 0.6226 - acc: 0.6628 - val_loss: 0.5910 - val_acc: 0.8229\n",
      "Epoch 4/7\n",
      "768/768 [==============================] - 8s 11ms/sample - loss: 0.5457 - acc: 0.8789 - val_loss: 0.5226 - val_acc: 0.8385\n",
      "Epoch 5/7\n",
      "768/768 [==============================] - 9s 12ms/sample - loss: 0.4111 - acc: 0.9310 - val_loss: 0.4959 - val_acc: 0.7760\n",
      "Epoch 6/7\n",
      "768/768 [==============================] - 8s 11ms/sample - loss: 0.2351 - acc: 0.9453 - val_loss: 0.3829 - val_acc: 0.8021\n",
      "Epoch 7/7\n",
      "768/768 [==============================] - 10s 12ms/sample - loss: 0.2985 - acc: 0.8776 - val_loss: 0.3108 - val_acc: 0.8594\n",
      "240/240 [==============================] - 1s 3ms/sample - loss: 0.3141 - acc: 0.8667\n",
      "morps_LSTM 테스트 정확도: 0.8667\n"
     ]
    }
   ],
   "source": [
    "morps_LSTM_history = morps_LSTM_model.fit(morps_X_train, morps_y_train, epochs=7, batch_size=60, validation_data=(morps_X_valid,morps_y_valid))\n",
    "print(\"morps_LSTM 테스트 정확도: %.4f\" % (morps_LSTM_model.evaluate(morps_X_test, morps_y_test)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 768 samples, validate on 192 samples\n",
      "Epoch 1/17\n",
      "768/768 [==============================] - 1s 1ms/sample - loss: 0.6908 - acc: 0.5339 - val_loss: 0.6897 - val_acc: 0.5156\n",
      "Epoch 2/17\n",
      "768/768 [==============================] - 0s 365us/sample - loss: 0.6725 - acc: 0.6107 - val_loss: 0.6829 - val_acc: 0.5365\n",
      "Epoch 3/17\n",
      "768/768 [==============================] - 0s 416us/sample - loss: 0.6467 - acc: 0.6198 - val_loss: 0.6694 - val_acc: 0.5677\n",
      "Epoch 4/17\n",
      "768/768 [==============================] - 0s 265us/sample - loss: 0.5959 - acc: 0.6940 - val_loss: 0.6372 - val_acc: 0.6198\n",
      "Epoch 5/17\n",
      "768/768 [==============================] - 0s 279us/sample - loss: 0.5010 - acc: 0.8568 - val_loss: 0.5587 - val_acc: 0.7812\n",
      "Epoch 6/17\n",
      "768/768 [==============================] - 0s 278us/sample - loss: 0.3493 - acc: 0.9688 - val_loss: 0.4292 - val_acc: 0.8385\n",
      "Epoch 7/17\n",
      "768/768 [==============================] - 0s 287us/sample - loss: 0.1936 - acc: 0.9818 - val_loss: 0.3368 - val_acc: 0.8646\n",
      "Epoch 8/17\n",
      "768/768 [==============================] - 0s 261us/sample - loss: 0.1019 - acc: 0.9857 - val_loss: 0.2844 - val_acc: 0.8906\n",
      "Epoch 9/17\n",
      "768/768 [==============================] - 0s 286us/sample - loss: 0.0561 - acc: 0.9909 - val_loss: 0.2696 - val_acc: 0.9010\n",
      "Epoch 10/17\n",
      "768/768 [==============================] - 0s 260us/sample - loss: 0.0336 - acc: 0.9961 - val_loss: 0.2565 - val_acc: 0.9115\n",
      "Epoch 11/17\n",
      "768/768 [==============================] - 0s 287us/sample - loss: 0.0230 - acc: 0.9974 - val_loss: 0.2563 - val_acc: 0.9062\n",
      "Epoch 12/17\n",
      "768/768 [==============================] - 0s 297us/sample - loss: 0.0172 - acc: 0.9974 - val_loss: 0.2509 - val_acc: 0.9219\n",
      "Epoch 13/17\n",
      "768/768 [==============================] - 0s 326us/sample - loss: 0.0128 - acc: 0.9974 - val_loss: 0.2449 - val_acc: 0.9219\n",
      "Epoch 14/17\n",
      "768/768 [==============================] - 0s 330us/sample - loss: 0.0109 - acc: 0.9974 - val_loss: 0.2454 - val_acc: 0.9219\n",
      "Epoch 15/17\n",
      "768/768 [==============================] - 0s 312us/sample - loss: 0.0086 - acc: 0.9974 - val_loss: 0.2524 - val_acc: 0.9062\n",
      "Epoch 16/17\n",
      "768/768 [==============================] - 0s 265us/sample - loss: 0.0082 - acc: 0.9974 - val_loss: 0.2584 - val_acc: 0.9167\n",
      "Epoch 17/17\n",
      "768/768 [==============================] - 0s 312us/sample - loss: 0.0059 - acc: 0.9987 - val_loss: 0.2469 - val_acc: 0.9167\n",
      "240/240 [==============================] - 0s 170us/sample - loss: 0.2381 - acc: 0.9083\n",
      "morps_CNN 테스트 정확도: 0.9083\n"
     ]
    }
   ],
   "source": [
    "morps_CNN_history = morps_CNN_model.fit(morps_X_train, morps_y_train, epochs=17, batch_size=60, validation_data=(morps_X_valid,morps_y_valid))\n",
    "print(\"morps_CNN 테스트 정확도: %.4f\" % (morps_CNN_model.evaluate(morps_X_test, morps_y_test)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 768 samples, validate on 192 samples\n",
      "Epoch 1/15\n",
      "768/768 [==============================] - 2s 2ms/sample - loss: 0.6672 - acc: 0.6107 - val_loss: 0.6351 - val_acc: 0.6562\n",
      "Epoch 2/15\n",
      "768/768 [==============================] - 1s 1ms/sample - loss: 0.5772 - acc: 0.7995 - val_loss: 0.5857 - val_acc: 0.7396\n",
      "Epoch 3/15\n",
      "768/768 [==============================] - 1s 1ms/sample - loss: 0.4818 - acc: 0.8789 - val_loss: 0.5388 - val_acc: 0.7344\n",
      "Epoch 4/15\n",
      "768/768 [==============================] - 1s 1ms/sample - loss: 0.4543 - acc: 0.8359 - val_loss: 0.4959 - val_acc: 0.7917\n",
      "Epoch 5/15\n",
      "768/768 [==============================] - 1s 1ms/sample - loss: 0.3384 - acc: 0.9362 - val_loss: 0.4493 - val_acc: 0.7865\n",
      "Epoch 6/15\n",
      "768/768 [==============================] - 1s 1ms/sample - loss: 0.2699 - acc: 0.9492 - val_loss: 0.4161 - val_acc: 0.7812\n",
      "Epoch 7/15\n",
      "768/768 [==============================] - 1s 1ms/sample - loss: 0.2386 - acc: 0.9440 - val_loss: 0.4149 - val_acc: 0.8073\n",
      "Epoch 8/15\n",
      "768/768 [==============================] - 1s 1ms/sample - loss: 0.1807 - acc: 0.9714 - val_loss: 0.3624 - val_acc: 0.8333\n",
      "Epoch 9/15\n",
      "768/768 [==============================] - 1s 1ms/sample - loss: 0.1628 - acc: 0.9622 - val_loss: 0.3736 - val_acc: 0.8177\n",
      "Epoch 10/15\n",
      "768/768 [==============================] - 1s 1ms/sample - loss: 0.1158 - acc: 0.9805 - val_loss: 0.3776 - val_acc: 0.8385\n",
      "Epoch 11/15\n",
      "768/768 [==============================] - 1s 1ms/sample - loss: 0.0970 - acc: 0.9792 - val_loss: 0.3332 - val_acc: 0.8698\n",
      "Epoch 12/15\n",
      "768/768 [==============================] - 1s 1ms/sample - loss: 0.0773 - acc: 0.9844 - val_loss: 0.3203 - val_acc: 0.8594\n",
      "Epoch 13/15\n",
      "768/768 [==============================] - 1s 1ms/sample - loss: 0.0559 - acc: 0.9909 - val_loss: 0.3862 - val_acc: 0.8281\n",
      "Epoch 14/15\n",
      "768/768 [==============================] - 1s 1ms/sample - loss: 0.0518 - acc: 0.9909 - val_loss: 0.3645 - val_acc: 0.8594\n",
      "Epoch 15/15\n",
      "768/768 [==============================] - 1s 1ms/sample - loss: 0.0437 - acc: 0.9935 - val_loss: 0.4033 - val_acc: 0.8542\n",
      "240/240 [==============================] - 0s 541us/sample - loss: 0.2999 - acc: 0.8708\n",
      "morpsJaso_RNN 테스트 정확도: 0.8708\n"
     ]
    }
   ],
   "source": [
    "morpsJaso_RNN_history = morpsJaso_RNN_model.fit(morpsJaso_X_train, morpsJaso_y_train, epochs=15, batch_size=60, validation_data=(morpsJaso_X_valid,morpsJaso_y_valid))\n",
    "print(\"morpsJaso_RNN 테스트 정확도: %.4f\" % (morpsJaso_RNN_model.evaluate(morpsJaso_X_test, morpsJaso_y_test)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 768 samples, validate on 192 samples\n",
      "Epoch 1/7\n",
      "768/768 [==============================] - 25s 33ms/sample - loss: 1.5876 - acc: 0.4922 - val_loss: 0.9536 - val_acc: 0.5052\n",
      "Epoch 2/7\n",
      "768/768 [==============================] - 23s 30ms/sample - loss: 1.0079 - acc: 0.4948 - val_loss: 0.9316 - val_acc: 0.5052\n",
      "Epoch 3/7\n",
      "768/768 [==============================] - 24s 32ms/sample - loss: 0.8191 - acc: 0.4948 - val_loss: 0.6668 - val_acc: 0.5052\n",
      "Epoch 4/7\n",
      "768/768 [==============================] - 23s 30ms/sample - loss: 0.5961 - acc: 0.6823 - val_loss: 0.5901 - val_acc: 0.7656\n",
      "Epoch 5/7\n",
      "768/768 [==============================] - 23s 30ms/sample - loss: 0.5290 - acc: 0.8411 - val_loss: 0.5307 - val_acc: 0.7760\n",
      "Epoch 6/7\n",
      "768/768 [==============================] - 27s 35ms/sample - loss: 0.4337 - acc: 0.8438 - val_loss: 0.4717 - val_acc: 0.8125\n",
      "Epoch 7/7\n",
      "768/768 [==============================] - 23s 30ms/sample - loss: 0.3532 - acc: 0.9062 - val_loss: 0.4570 - val_acc: 0.8229\n",
      "240/240 [==============================] - 2s 7ms/sample - loss: 0.3474 - acc: 0.8833\n",
      "morpsJaso_LSTM 테스트 정확도: 0.8833\n"
     ]
    }
   ],
   "source": [
    "morpsJaso_LSTM_model = LSTMmodel(morpsJaso_vocab_size, morpsJaso_max_len)\n",
    "\n",
    "\n",
    "morpsJaso_LSTM_history = morpsJaso_LSTM_model.fit(morpsJaso_X_train, morpsJaso_y_train, epochs=7, batch_size=60, validation_data=(morpsJaso_X_valid,morpsJaso_y_valid))\n",
    "print(\"morpsJaso_LSTM 테스트 정확도: %.4f\" % (morpsJaso_LSTM_model.evaluate(morpsJaso_X_test, morpsJaso_y_test)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 768 samples, validate on 192 samples\n",
      "Epoch 1/17\n",
      "768/768 [==============================] - 2s 2ms/sample - loss: 0.6911 - acc: 0.5065 - val_loss: 0.6897 - val_acc: 0.5260\n",
      "Epoch 2/17\n",
      "768/768 [==============================] - 0s 368us/sample - loss: 0.6749 - acc: 0.6328 - val_loss: 0.6846 - val_acc: 0.5156\n",
      "Epoch 3/17\n",
      "768/768 [==============================] - 0s 375us/sample - loss: 0.6547 - acc: 0.6159 - val_loss: 0.6752 - val_acc: 0.5677\n",
      "Epoch 4/17\n",
      "768/768 [==============================] - 0s 369us/sample - loss: 0.6208 - acc: 0.7109 - val_loss: 0.6499 - val_acc: 0.5729\n",
      "Epoch 5/17\n",
      "768/768 [==============================] - 0s 377us/sample - loss: 0.5680 - acc: 0.7721 - val_loss: 0.5879 - val_acc: 0.7396\n",
      "Epoch 6/17\n",
      "768/768 [==============================] - 0s 366us/sample - loss: 0.4513 - acc: 0.9049 - val_loss: 0.4775 - val_acc: 0.8385\n",
      "Epoch 7/17\n",
      "768/768 [==============================] - 0s 371us/sample - loss: 0.3020 - acc: 0.9505 - val_loss: 0.3658 - val_acc: 0.8698\n",
      "Epoch 8/17\n",
      "768/768 [==============================] - 0s 382us/sample - loss: 0.1789 - acc: 0.9609 - val_loss: 0.3209 - val_acc: 0.8802\n",
      "Epoch 9/17\n",
      "768/768 [==============================] - 0s 409us/sample - loss: 0.1134 - acc: 0.9714 - val_loss: 0.3037 - val_acc: 0.8802\n",
      "Epoch 10/17\n",
      "768/768 [==============================] - 0s 390us/sample - loss: 0.0677 - acc: 0.9909 - val_loss: 0.2983 - val_acc: 0.8750\n",
      "Epoch 11/17\n",
      "768/768 [==============================] - 0s 414us/sample - loss: 0.0451 - acc: 0.9922 - val_loss: 0.2978 - val_acc: 0.8802\n",
      "Epoch 12/17\n",
      "768/768 [==============================] - 0s 383us/sample - loss: 0.0308 - acc: 0.9948 - val_loss: 0.3050 - val_acc: 0.8802\n",
      "Epoch 13/17\n",
      "768/768 [==============================] - 0s 368us/sample - loss: 0.0234 - acc: 0.9961 - val_loss: 0.3215 - val_acc: 0.8750\n",
      "Epoch 14/17\n",
      "768/768 [==============================] - 0s 473us/sample - loss: 0.0192 - acc: 0.9961 - val_loss: 0.3232 - val_acc: 0.8854\n",
      "Epoch 15/17\n",
      "768/768 [==============================] - 0s 396us/sample - loss: 0.0157 - acc: 0.9974 - val_loss: 0.3279 - val_acc: 0.8750\n",
      "Epoch 16/17\n",
      "768/768 [==============================] - 0s 399us/sample - loss: 0.0122 - acc: 0.9974 - val_loss: 0.3314 - val_acc: 0.8854\n",
      "Epoch 17/17\n",
      "768/768 [==============================] - 0s 378us/sample - loss: 0.0095 - acc: 0.9987 - val_loss: 0.3373 - val_acc: 0.8854\n",
      "240/240 [==============================] - 0s 204us/sample - loss: 0.2333 - acc: 0.9000\n",
      "morpsJaso_CNN 테스트 정확도: 0.9000\n"
     ]
    }
   ],
   "source": [
    "morpsJaso_CNN_history = morpsJaso_CNN_model.fit(morpsJaso_X_train, morpsJaso_y_train, epochs=17, batch_size=60, validation_data=(morpsJaso_X_valid,morpsJaso_y_valid))\n",
    "print(\"morpsJaso_CNN 테스트 정확도: %.4f\" % (morpsJaso_CNN_model.evaluate(morpsJaso_X_test, morpsJaso_y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 0s 602us/sample - loss: 0.3347 - acc: 0.8542\n",
      "nouns_RNN 테스트 정확도: 0.8542\n",
      "240/240 [==============================] - 0s 848us/sample - loss: 0.3442 - acc: 0.8708\n",
      "nouns_LSTM 테스트 정확도: 0.8708\n",
      "240/240 [==============================] - 0s 552us/sample - loss: 0.2567 - acc: 0.9042\n",
      "nouns_CNN 테스트 정확도: 0.9042\n",
      "240/240 [==============================] - 0s 431us/sample - loss: 0.2735 - acc: 0.8917\n",
      "nounsJaso_RNN 테스트 정확도: 0.8917\n",
      "240/240 [==============================] - 0s 2ms/sample - loss: 0.3371 - acc: 0.8917\n",
      "nounsJaso_LSTM 테스트 정확도: 0.8917\n",
      "240/240 [==============================] - 0s 399us/sample - loss: 0.2332 - acc: 0.9125\n",
      "nounsJaso_CNN 테스트 정확도: 0.9125\n",
      "240/240 [==============================] - 0s 587us/sample - loss: 0.3579 - acc: 0.8458\n",
      "morps_RNN 테스트 정확도: 0.8458\n",
      "240/240 [==============================] - 1s 3ms/sample - loss: 0.3141 - acc: 0.8667\n",
      "morps_LSTM 테스트 정확도: 0.8667\n",
      "240/240 [==============================] - 0s 387us/sample - loss: 0.2381 - acc: 0.9083\n",
      "morps_CNN 테스트 정확도: 0.9083\n",
      "240/240 [==============================] - 0s 558us/sample - loss: 0.2999 - acc: 0.8708\n",
      "morpsJaso_RNN 테스트 정확도: 0.8708\n",
      "240/240 [==============================] - 2s 7ms/sample - loss: 0.3474 - acc: 0.8833\n",
      "morpsJaso_LSTM 테스트 정확도: 0.8833\n",
      "240/240 [==============================] - 0s 391us/sample - loss: 0.2333 - acc: 0.9000\n",
      "morpsJaso_CNN 테스트 정확도: 0.9000\n"
     ]
    }
   ],
   "source": [
    "#명사 테스트 정확도\n",
    "print(\"nouns_RNN 테스트 정확도: %.4f\" % (nouns_RNN_model.evaluate(nouns_X_test, nouns_y_test)[1]))\n",
    "print(\"nouns_LSTM 테스트 정확도: %.4f\" % (nouns_LSTM_model.evaluate(nouns_X_test, nouns_y_test)[1]))\n",
    "print(\"nouns_CNN 테스트 정확도: %.4f\" % (nouns_CNN_model.evaluate(nouns_X_test, nouns_y_test)[1]))\n",
    "\n",
    "#명사 자소 분리 테스트 정확도\n",
    "print(\"nounsJaso_RNN 테스트 정확도: %.4f\" % (nounsJaso_RNN_model.evaluate(nounsJaso_X_test, nounsJaso_y_test)[1]))\n",
    "print(\"nounsJaso_LSTM 테스트 정확도: %.4f\" % (nounsJaso_LSTM_model.evaluate(nounsJaso_X_test, nounsJaso_y_test)[1]))\n",
    "print(\"nounsJaso_CNN 테스트 정확도: %.4f\" % (nounsJaso_CNN_model.evaluate(nounsJaso_X_test, nounsJaso_y_test)[1]))\n",
    "\n",
    "#모든 형태소 정확도\n",
    "print(\"morps_RNN 테스트 정확도: %.4f\" % (morps_RNN_model.evaluate(morps_X_test, morps_y_test)[1]))\n",
    "print(\"morps_LSTM 테스트 정확도: %.4f\" % (morps_LSTM_model.evaluate(morps_X_test, morps_y_test)[1]))\n",
    "print(\"morps_CNN 테스트 정확도: %.4f\" % (morps_CNN_model.evaluate(morps_X_test, morps_y_test)[1]))\n",
    "\n",
    "#모든 형태소 자소 분리 정확도\n",
    "print(\"morpsJaso_RNN 테스트 정확도: %.4f\" % (morpsJaso_RNN_model.evaluate(morpsJaso_X_test, morpsJaso_y_test)[1]))\n",
    "print(\"morpsJaso_LSTM 테스트 정확도: %.4f\" % (morpsJaso_LSTM_model.evaluate(morpsJaso_X_test, morpsJaso_y_test)[1]))\n",
    "print(\"morpsJaso_CNN 테스트 정확도: %.4f\" % (morpsJaso_CNN_model.evaluate(morpsJaso_X_test, morpsJaso_y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
